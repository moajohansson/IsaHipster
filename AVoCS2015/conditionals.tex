\label{sec:conditionals}

We now demonstrate how to employ Hipster interactively for theory exploration of conditional lemmas in the development of a theory.%, with the aim of proving insertion sort's correctness.
%
We first explain how conditional conjectures are generated in QuickSpec.
%
We then explain our new automated induction tactic for recursion induction, and finally show how Hipster combines these in a case study proving the correctness of insertion sort.  

\subsection{Generating Conditional Conjectures}
\label{sub:gencond}

The support in QuickSpec for generating conditional conjectures (implications) is still rather basic.
%
In this case, QuickSpec will in addition to the other input require the user to specify a predicate to use as the premise of an implication.
%
Term generation proceeds as described above, but testing takes the given predicate into account.
%
Here, we are only interested in tests with values that make the premise true, otherwise we may split the equivalence classes when they should not be split.
% newpara?
QuickCheck uses special functions called \emph{generators} to produce random values of a given type.
%
If using QuickSpec directly in Haskell, the user can program special purpose generators that could be made to only produce values satisfying a given predicate.
%
In Hipster, however, these generator functions are simpler as they have to be automatically derived together with the Haskell code.
%
Tests not satisfying the premise are simply discarded during conditional exploration, which means that we typically must generate more tests than for equational conjectures.
%
Also, the risk of some non-theorem slipping through is slightly higher, but as Hipster then attempts to prove all conjectures, such a statement would be caught in the proving phase.
%
Automatically generating customised generator functions is further work. 

\paragraph*{Example 2.}
\label{example2}
In Example 1, we showed how QuickSpec generated equational conjectures about the insertion sort function \isaCode{isort}.
%
We are furthermore interested in the case with the condition that the predicate \isaCode{sorted} holds (for one variable).
%
In this case, QuickSpec first performs one pass looking for plain equations, as in Example 1, then a second where it considers the condition \isaCode{sorted xs}.
%
In this second phase, QuickSpec performs a new exploration, this time requiring the predicate \isaCode{sorted xs} to hold for all test values.
%
Suppose we test with the sorted list: \isaCode{xs $\rightarrow$ [1,2]} (other non-sorted values for \isaCode{xs} would be discarded).       

\vspace{2 mm}

\noindent \begin{tabularx}{\textwidth}{l  X  X  X}
 & Term & Ground Instance & Value \\
 \hline
1 \quad &\isaCode{isort xs} & \isaCode{isort([1,2])} & \isaCode{[1,2]} \\
2 \quad &\isaCode{isort (isort xs)} &\isaCode{isort (isort [1,2])} & \isaCode{[1,2]}\\
3 \quad &\isaCode{xs} &\isaCode{[1,2]} & \isaCode{[1,2]} \\
\end{tabularx}

\vspace{2 mm}

\noindent This time, all terms evaluate to the same value on all tests where the list is sorted, so all three terms remain in the same equivalence class.
%
QuickSpec realises that there is no point producing the conjecture \isaCode{sorted xs $\Longrightarrow$ isort (isort xs) = xs}, as this is subsumed by the non-conditional equation discovered in the first phase.
%
It will however produce the additional conjecture \\ \isaCode{sorted xs $\Longrightarrow$ isort xs = xs}, which clearly only holds if the list is already sorted.


%\subsection{A Need for Conditionals}
%
%Conditional lemmas are required in breaking down reasoning into small units of focus.
%%
%Different scenarios and constructs require or give rise to constrained propositions:
%
%\begin{itemize}\itemsep0mm
%\item branching on conditions determining cases during a proof attempt
%\item proving algorithm correctness, where changes of consecutive steps are to be taken into account
%\item programming invariants
%\begin{itemize}\itemsep1mm
%\item in datatypes, where sometimes these cannot be encoded in the constructors and instead depend of the arrangement of data values conforming an instance and invariant preservation by from functions manipulating the datatype
%\item in functions and algorithms, where auxiliary functions might assume certain conditions on their input to be able to guarantee conditions over the output result.
%\end{itemize}
%\end{itemize}
%
%By employing recursion induction, a proof can be driven and shaped by the structure of its components (types or functions), further explained in \S \ref{sec:rec-ind}.
%%
%This allows to account for the imposition a side-condition may have on variables in an explicit, direct way, whether it is via its own recursion induction scheme or its evaluation on cases isolated by another function's recursion induction.

\subsection{Automating Recursion Induction}
\label{sec:rec-ind}

A recursion induction scheme is derived from a function's recursive definition.
%
Unlike structural induction, the recursion induction scheme corresponds to the originating definition, and hence, the cases considered in its simplification rules.

When defining a recursive function over an inductive datatype one might traverse arguments following a different pattern to the strictly structural one (the one arising from a datatype's definition).
%
This pattern could be more specific, or even less so, than following the datatype.

For instance, take the functions on lists \isaCode{sorted} and \isaCode{last}:

\begin{lstlisting}[ mathescape, columns=fullflexible,keepspaces, basicstyle=\fontfamily{lmvtt}\selectfont, ]
fun sorted :: "Nat List $\Rightarrow$ Bool" where
  "sorted [] = True"
| "sorted ([x]) = True"
| "sorted (x1 # (x2 # xs)) = (x1 $\le$ x2 & sorted (x2 # xs))"

fun last :: "'a List $\Rightarrow$ 'a" where
  "last ([x]) = x"
| "last (x # xs) = last xs"
\end{lstlisting}

\noindent From these definitions' structures one can derive a new induction principle.
%
Structural induction on lists considers the base-case \isaCode{[]} (the empty list) and step-case \isaCode{x \# xs} (a list with an element inserted at the front).
%
In the case of \isaCode{sorted}, cases are broken down into more detailed ones by including an additional base-case \isaCode{[x]} (the singleton list) and restricting the step-case to lists with at least two elements \isaCode{x1 \# x2 \# xs}.
%
Meanwhile \isaCode{last} is not defined for the case \isaCode{[]} and hence partially defined, meaning the induction scheme it gives rise to is to be completed with such a case.
%
This, in fact, results in the same recursion induction scheme derived from \isaCode{sorted}:

\vspace{2 mm}

\inferrule [SortedInd]
  {P\;([]) \\ \forall u\;\; P\;([u]) \\ \forall r, \; t, \; ts\;\; (P\;(r \;\#\; ts) \; \Longrightarrow\;P\;(t\;\#\; (r\;\#\; ts)))}
  {\forall x \;\; P\;(x)}

\inferrule [LastInd]
  {\forall u\;\; P\;([u]) \\ \forall r, \; t, \; ts\;\; (P\;(r\;\#\; ts) \; \Longrightarrow\;P\;(t \;\#\; (r\;\#\; ts))) \\ P\;([])}
  {\forall x \;\; P\;(x)}

\vspace{2 mm}

Induction determined by these schemata is called \emph{recursion induction} or \emph{computation induction}.
%
They can isolate sub-units not represented in a datatype's structure as being atomic, such as lists with at least two elements in the scheme for \isaCode{sorted}.
%
Recursion induction hence provides an immediate and more specific structure for reasoning about other recursion patterns where a simple structural induction might fail to set appropriate base and step-cases for the induction to succeed.

Within Isabelle/HOL these schemata are automatically derived and proved as theorems from recursive functions' termination order, and hence guaranteed to be sound \cite{krauss-term}. 


\paragraph*{Example 3: Recursion Induction in a Proof.}

%% Example from presentation on difference

To exemplify the potential difference between recursion and structural induction, let us take the already introduced conditional lemma \\ \isaCode{sorted xs $\Longrightarrow$ sorted (insert x xs)}.
%
Applying structural induction on the list \isaCode{xs} would produce the subgoals:

\begin{lstlisting}[ mathescape, columns=fullflexible,keepspaces, basicstyle=\fontfamily{lmvtt}\selectfont, ]
1. sorted [] $\Longrightarrow$ sorted (insert x [])
2. $\wedge$ y ys. (sorted ys $\Longrightarrow$ sorted (insert x ys)) $\Longrightarrow$ sorted (y # ys) $\Longrightarrow$
            sorted (insert x (y # ys))
\end{lstlisting}

\noindent Whilst \isaCode{sorted}'s recursion induction scheme would yield:

\begin{lstlisting}[ mathescape, columns=fullflexible,keepspaces, basicstyle=\fontfamily{lmvtt}\selectfont, ]
1. sorted [] $\Longrightarrow$ sorted (insert x [])
2. $\wedge$ y. sorted [y] $\Longrightarrow$ sorted (insert x [y])
3. $\wedge$ y1 y2 ys. (sorted (y2 # ys) $\Longrightarrow$ sorted (insert x (y2 # ys))) $\Longrightarrow$ 
               sorted (y1 # y2 # ys) $\Longrightarrow$ sorted (insert x (y1 # y2 # ys))
\end{lstlisting}

\noindent The latter set of subgoals leads to an immediate proof of the main lemma thanks to its steps mirroring the actual predicate definition, hence having a correspondence with its simplification rules.
%
In contrast, the former, even though it intuitively looks immediate to prove, is not sufficiently generalised nor does it specify any intermediate result on inserting an element on a concrete non-empty list (in our case, the singleton list) which would enable to prove the second subgoal for any arbitrary list.
%
Structural induction is in some way a weaker scheme and additional case-splits or lemmas would be required to close the proof employing it in our example.


\subsubsection*{A New Induction Tactic for Hipster}

%I just realised that we're missing this section. Here, we should explain how your new tactic is implemented (i.e. the tactic hipster-induct-schemes used below in the case study). I.e. how it searches for a proof. Does it first try structural induction, and if that that didn't work, proceed to structural induction. Explain how it chooses which functions induction scheme to try if there are several.

We have implemented a new automated tactic, called \isaCode{hipster\_induct\_schemes}, for induction in Isabelle.
%
This tactic searches not only for proofs by structural induction, but may also employ recursion induction when appropriate.
%
It is designed for Hipster to use as its "difficult reasoning" component, but human users may of course also employ this tactic in interactive proofs. 

%This is my understanding of what the tactic does. Irene, might need revising!
% I.e. which are the configuration options for the tactic?
The tactic first tries structural induction using the induction scheme associated with the datatype(s) of variables in the problem.
%
If this fails, the tactic then tries recursion induction, using the induction schemes associated with the functions occurring in the problem.
%
When instantiating recursion induction schemes with variables of the problem, more complete instantiations are considered first.
%
This leaves less specific partial instantiations to be tried later.
% TODO: TODO: [MENTION heuristics here! Are there any for which functions induction scheme to try first? Timeouts?].
For each attempted induction, the tactic will apply Isabelle's simplifier followed by (if necessary) first-order reasoning using Isabelle's built in first-order prover Metis.
%
Figure \ref{fig:tactic} shows an overview of the tactic.

The user can configure the tactic to specify how to select facts to be passed to the simplifier and to Metis.
%
The default is the simplification rules from the relevant function definitions, the datatype case distinction rules which are automatically derived by Isabelle, and the lemmas discovered by theory exploration so far.
%
%
However, if we pass too many facts to Metis, it becomes slower. Therefore, the user can configure Hipster to include fewer of the discovered lemmas if needed. Hipster also impose a timeout on simplification and first-order reasoning, which can be set by the user. The default timeout is 1 second for each proof attempt.
%
As further work, we plan to experiment with using Sledgehammer instead \cite{sledgehammer}, which calls powerful external first-order provers and reports back exactly which facts were needed in the proof.
%
Metis can then reconstruct the proof quickly inside Isabelle's trusted kernel.

\begin{figure}
\begin{lstlisting}[   mathescape,   columns=fullflexible,   basicstyle=\fontfamily{lmvtt}\selectfont, ]
TRY
  Structural induction schemes(s)
     THEN simplification + F.O. reasoning
OTHERWISE_TRY
  Recursion induction sceheme(s)
     THEN simplification + F.O. reasoning
\end{lstlisting}		
\caption{Overview of Hipsters new tactic.}	
\label{fig:tactic}
\end{figure}


\paragraph*{Example 4: Simultaneous Induction.}
%The new tactic for Hipster explores the proofs one could attain by recursion inductions derived from functions occurring in the conjecture.
%
%As a side-result, this increases the scope of Hipster's original approach for equational lemmas too.

A notable gain of the new tactic with recursion induction is that of having the capability of performing simultaneous induction, whereas previously only structural inductions on a single variable were performed by Hipster.
%
Simultaneous induction schemata are those inducting over more than one variable at a time, whether those variables are of the same type or not.
%
Such is the case for the list function \isaCode{zip}'s recursion induction scheme, which corresponds to parallel induction on two lists:

\begin{lstlisting}[   mathescape,   columns=fullflexible,   basicstyle=\fontfamily{lmvtt}\selectfont, ]
fun zip :: "'a list $\Rightarrow$ 'b list $\Rightarrow$ ('a $\times$ 'b) list" where
  "zip [] y = []"
| "zip (x # xs) [] = []"
| "zip (x # xs) (y # ys) = (x, y) # (zip xs ys)"
\end{lstlisting}

\vspace{2 mm}

\inferrule [ZipInd]
  {\forall ts\;\; P\;([],\; ts) \\ \forall z,\; rs\;\; P\;(z\;\#\; rs, [])  \\ \forall z,\; y,\; rs,\; ts\;\; (P\;(rs,\;ts) \Longrightarrow\; P\;(z\; \# \; rs,\; y\;\#\; ts))}
  {\forall xs, \; ys \;\; P\;(xs,\; ys)}

\vspace{2 mm}

\noindent This scheme, along with some initial theory exploration, allows theorems like the following to be proven automatically:

\begin{lstlisting}[   mathescape,   columns=fullflexible,   basicstyle=\fontfamily{lmvtt}\selectfont, ]
zip (xs @ ys) zs = (zip xs (take (len xs) zs)) @ (zip ys (drop (len xs) zs))
\end{lstlisting}

\noindent Or even the alternative related conditional lemma to be proven without prior exploration:

\begin{lstlisting}[   mathescape,   columns=fullflexible,   basicstyle=\fontfamily{lmvtt}\selectfont, ]
len xs = len ys $\Longrightarrow$ (zip xs ys) @ (zip zs ws) = zip (xs @ zs) (ys @ ws)
\end{lstlisting}

\noindent Neither of these lemmas were provable before, even having done exploration for all the occurring functions in them.
%
Hipster's prior structural induction approach could not capture in a scheme the relation between two variables.
%
In these two cases, \isaCode{zip} traverses its arguments taking steps on both at the same time, a pattern we can only capture with some form of simultaneous induction.
%
Instead of synthesising a series of possible simultaneous structural induction schemata, recursion induction gives us an immediate choice which is also closer to the problem at hand.


\subsection{Interactive Case Study: Insertion Sort}

We here showcase Hipster's handling of conditional lemmas via the proof of correctness for the theorem \isaCode{sorted (isort ts)}.
%
For it, we assume the less-or-equal operator \isaCode{$\le$} for naturals (and no prior, additional lemmas), and the function definitions:

\begin{lstlisting}[ mathescape, columns=fullflexible,keepspaces, basicstyle=\fontfamily{lmvtt}\selectfont, ]
fun sorted :: "Nat List $\Rightarrow$ Bool" where
  "sorted [] = True"
| "sorted ([x]) = True"
| "sorted (x1 # (x2 # xs)) = (x1 $\le$ x2 & sorted (x2 # xs))"

fun insert :: "Nat $\Rightarrow$ Nat List $\Rightarrow$ Nat List" where
  "insert x [] = [x]"
| "insert x1 (x2 # xs) = (if (x1 $\le$ x2) then x1 # (x2 # xs)	
                                           else x2 # (insert x1 xs))"

fun isort :: "Nat List $\Rightarrow$ Nat List" where
  "isort [] = []"
| "isort (x # xs) = insert x (isort xs)"
\end{lstlisting}

Running exploration from the simpler components is the first step, considering both equational and conditional lemmas, since we have two predicates involved in the definiens of functions in the final theorem.
%
The following command invokes conditional exploration for \isaCode{$\le$}:

\begin{lstlisting}[ mathescape, columns=fullflexible,keepspaces, basicstyle=\fontfamily{lmvtt}\selectfont, ]
hipster_cond $\le$
\end{lstlisting}

\noindent which, along with conditional exploration for its negation, results in $10$ discovered and proven lemmas, $6$ of which are conditionals (we present the vital lemmas towards the final proof) and all require recursion induction:

\begin{lstlisting}[ mathescape, columns=fullflexible,keepspaces, basicstyle=\fontfamily{lmvtt}\selectfont, ]
lemma lemma_ac [thy_expl]: "x $\le$ y $\Longrightarrow$ x $\le$ (S y) = True"
by (hipster_induct_schemes $\le$.simps Nat.exhaust)

lemma lemma_ad [thy_expl]: "y $\le$ x $\Longrightarrow$ (S x) $\le$ y = False"
by (hipster_induct_schemes $\le$.simps Nat.exhaust)
(...)
lemma lemma_ai [thy_expl]: "($\lnot$ (x $\le$ y)) $\Longrightarrow$ x $\le$ Z = False"
by (hipster_induct_schemes $\le$.simps Nat.exhaust)
(...)
\end{lstlisting}

\noindent Hipster automatically generates this output.
%
For each case, the \isaCode{lemma} command makes the statement to be proven and is followed by a tactic application via the \isaCode{by} command, here using Hipster's recursion induction tactic \isaCode{hipster\_induct\_schemes}, which employs recursion induction where necessary.
%
To enable the completion of the proof, exploration provides it with the automatically generated Isabelle rules for simplification of function definitions, such as \isaCode{$\le$.simps}, and datatype case distinction rules, such as \isaCode{Nat.exhaust}.

With a new exploration considering the functions about sorting itself and (potentially) taking \isaCode{sorted} as a side-condition for which to discover lemmas, Hipster discovers and proves both the conditional auxiliary lemma required and the goal theorem.
%
Note that the exploration command takes as its first argument the predicate with which to construct side-conditions:

\begin{lstlisting}[ mathescape, columns=fullflexible,keepspaces, basicstyle=\fontfamily{lmvtt}\selectfont, ]
hispter_cond sorted isort insert
(...)
lemma isortInvariant [thy_expl]: "sorted ys $\Longrightarrow$ sorted (insert x ys) = True"
by (hipster_induct_schemes sorted.simps isort.simps insert.simps)
(...)
theorem isortSorts [thy_expl]: "sorted (isort x) = True"
by (hipster_induct_schemes sorted.simps isort.simps insert.simps)
\end{lstlisting}

During this last exploration, other interesting lemmas are discovered, all of which can be now proven automatically by using the sub-lemma about \isaCode{insert}'s invariant \isaCode{isortInvariant}:

\begin{lstlisting}[ mathescape, columns=fullflexible,keepspaces, basicstyle=\fontfamily{lmvtt}\selectfont, ]
lemma isortFixes [thy_expl]: "sorted x $\Longrightarrow$ isort x = x"
by (hipster_induct_schemes sorted.simps isort.simps insert.simps)

lemma insertComm [thy_expl]: "insert x (insert y z) = insert y (insert x z)"
by (hipster_induct_schemes insert.simps)
\end{lstlisting}

Invoking the recursion induction tactic \isaCode{hipster\_induct\_schemes} once proves all of the statements above, simplifying the interaction with the proof assistant.
%
Particularly, the crucial lemma \isaCode{isortInvariant} is proven applying \isaCode{sorted}'s associated recursion induction scheme, highlighting once again the need for support of conditional lemmas in automated inductive proving and the possibilities recursion induction brings towards proof automation.

% XXX: include? IF we mention new options
% Lastly, the benefit of an interactive environment is being able to parameterise the proving methods with adequate options as one works along. This supervised automation can be of great utility to a user during a formal theory development.

